{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "# %matplotlib widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "from itertools import product\n",
    "from itertools import groupby\n",
    "import itertools\n",
    "import pickle\n",
    "import glob\n",
    "import chardet\n",
    "\n",
    "# Third-Party Library Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Set a professional style for the plot\n",
    "plt.style.use('_mpl-gallery')\n",
    "import matplotlib.dates as mdaates\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.cm as cm\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "from obspy import read, UTCDateTime\n",
    "from obspy.signal.trigger import classic_sta_lta, trigger_onset, plot_trigger\n",
    "from obspy import Trace\n",
    "from obspy.imaging.spectrogram import spectrogram\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from tqdm.auto import tqdm\n",
    "from icecream import ic\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm, kstest, skew, kurtosis\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Local Imports\n",
    "from energy.utils_general import *\n",
    "from energy.utils_energy import *\n",
    "from energy.preprocessing import *\n",
    "from energy.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path to all the folders from the folder BD paper that is in the current directory\n",
    "folders = glob.glob('BD paper/*')\n",
    "# Get all the folders in the BD paper folder that start with waveform \n",
    "folders_signals = [folder for folder in folders if folder.startswith('BD paper/waveform')]\n",
    "folders_signals.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_channel_dict(folders_signals):\n",
    "    result_dict = {}\n",
    "\n",
    "    for folder in folders_signals:\n",
    "        waveform_type = os.path.basename(folder)\n",
    "        for event_path in os.scandir(folder):\n",
    "            if event_path.is_dir():\n",
    "                events_name = event_path.name\n",
    "                for network_folder in os.scandir(event_path.path):\n",
    "                    if network_folder.is_dir():\n",
    "                        network_name = network_folder.name\n",
    "                        stations_z_channel_z = [station_z.path for station_z in os.scandir(network_folder.path) if 'BHZ' in station_z.name]\n",
    "                        traces = [read(station_z_path)[0] for station_z_path in stations_z_channel_z]\n",
    "                        result_dict.setdefault(waveform_type, {}).setdefault(events_name, {})[network_name] = traces\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "result_dict = z_channel_dict(folders_signals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def z_channel_dict(folders_signals):\n",
    "    result_dict = OrderedDict()\n",
    "\n",
    "    # Define a custom sorting key function that sorts by magnitude and then by date\n",
    "    def sorting_key(d):\n",
    "        name_parts = d.name.split('_')\n",
    "        magnitude = float(name_parts[0])\n",
    "        date = datetime.strptime('_'.join(name_parts[1:]), '%Y-%m-%d_%H.%M.%S')\n",
    "        return (-magnitude, date)  # Use negative magnitude for descending order\n",
    "\n",
    "    for folder in sorted(folders_signals):\n",
    "        waveform_type = os.path.basename(folder)\n",
    "        if waveform_type not in result_dict:\n",
    "            result_dict[waveform_type] = OrderedDict()\n",
    "        for event_path in sorted(os.scandir(folder), key=sorting_key):\n",
    "            if event_path.is_dir():\n",
    "                events_name = event_path.name\n",
    "                if events_name not in result_dict[waveform_type]:\n",
    "                    result_dict[waveform_type][events_name] = OrderedDict()\n",
    "                for network_folder in sorted(os.scandir(event_path.path), key=lambda d: d.name):\n",
    "                    if network_folder.is_dir():\n",
    "                        network_name = network_folder.name\n",
    "                        stations_z_channel_z = [station_z.path for station_z in sorted(os.scandir(network_folder.path), key=lambda d: d.name) if 'BHZ' in station_z.name]\n",
    "                        traces = [read(station_z_path)[0] for station_z_path in stations_z_channel_z]\n",
    "                        result_dict[waveform_type][events_name][network_name] = traces\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "result_dict1 = z_channel_dict(folders_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['4.3_2014-01-07_22.45.39', '4.3_2014-02-17_00.47.08', '4.3_2014-03-04_02.49.45', '4.3_2014-03-09_01.49.04', '4.3_2014-03-17_04.59.21', '4.3_2014-03-17_11.46.35', '4.3_2014-03-24_07.13.50', '4.3_2014-03-24_18.20.28', '4.3_2014-03-24_21.08.30', '4.2_2014-03-25_21.58.48', '4.2_2014-04-02_00.10.33', '4.2_2014-04-02_07.42.21', '4.2_2014-04-02_08.13.07', '4.2_2014-04-02_09.21.37', '4.2_2014-04-02_10.18.22', '4.1_2014-04-02_17.05.15', '4.1_2014-04-02_17.06.54', '4.1_2014-04-02_19.57.47', '4.1_2014-04-03_03.28.50', '4.1_2014-04-03_08.44.59', '4.1_2014-04-03_10.00.52', '4.1_2014-04-03_14.01.04', '4.0_2014-04-03_20.24.39', '4.0_2014-04-03_23.13.17', '4.0_2014-04-04_03.19.40', '4.0_2014-04-04_07.42.17', '4.0_2014-04-04_07.57.32', '4.0_2014-04-05_01.36.12', '4.0_2014-04-05_02.05.44', '4.0_2014-04-05_11.03.30', '4.0_2014-04-05_12.15.57'])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict1['waveform 4p1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La siguiente función pone a todas las traces de TODOS los eventos en una fila, esto lo tengo a priori, quizás habrá que arreglarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_traces(nested_dict):\n",
    "    traces = []\n",
    "    for value in nested_dict.values():\n",
    "        if isinstance(value, dict):\n",
    "            traces.extend(get_all_traces(value))\n",
    "        else:\n",
    "            traces.extend(value)\n",
    "    return traces\n",
    "\n",
    "# Get all ObsPy Trace objects in the dictionary\n",
    "all_traces = get_all_traces(result_dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BD paper/waveform 4p1',\n",
       " 'BD paper/waveform 5',\n",
       " 'BD paper/lista de datos',\n",
       " 'BD paper/waveform 4p2',\n",
       " 'BD paper/waveform 6-9']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = os.path.join('BD paper/lista de datos', 'Eventos 5.csv')\n",
    "\n",
    "# Detectar el encoding del archivo\n",
    "with open(file_path, 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "\n",
    "# Crear un dataframe a partir de tu archivo csv con el encoding detectado\n",
    "df = pd.read_csv(file_path, delimiter='|', encoding=result['encoding'])\n",
    "\n",
    "# Seleccionar solo las columnas que necesitas\n",
    "df = df[[\"Time\", \"Latitude\", \"Longitude\", \"Magnitude\"]]\n",
    "\n",
    "# Guardar el nuevo dataframe en un archivo Excel\n",
    "df.to_excel(os.path.join('BD paper/lista de datos','nuevo_archivo.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trigger_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
