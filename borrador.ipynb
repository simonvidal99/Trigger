{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_picking(st_main, adj_st_1, adj_st_2, ventana_10s, ventana_30s, nsta, nlta, v_P, coords_st, thr_on, thr_off):\n",
    "    \"\"\"\n",
    "    Función que realiza el picking de la onda P. En caso de que se detecte un sismo en las estación principal,\n",
    "    se verifica que las estaciones adyacentes también lo detecten.\n",
    "\n",
    "    Entradas:\n",
    "    ----------\n",
    "    st_main: obspy.core.stream.Stream\n",
    "        Stream de la estación principal.\n",
    "    adj_st_1: obspy.core.stream.Stream\n",
    "        Stream de la estación adyacente 1.\n",
    "    adj_st_2: obspy.core.stream.Stream\n",
    "        Stream de la estación adyacente 2.\n",
    "    ventana_10s: int\n",
    "        Tiempo de la ventana en segundos donde se aplica el STA/LTA.\n",
    "    ventana_30s: int\n",
    "        Tiempo de la señal en segundos que se analiza en cada iteración.\n",
    "    nsta: int\n",
    "        Largo del short time average en segundos.\n",
    "    nlta: int\n",
    "        Largo del long time average en segundos.\n",
    "    v_P: float\n",
    "        Velocidad de propagación de la onda P en km/s.\n",
    "    coords_st: list\n",
    "        Coordenadas (latitud, longitud) de las estaciones.\n",
    "    \n",
    "    Salidas:\n",
    "    ----------\n",
    "    time_trigger_main: list\n",
    "        Lista que contiene tiempos cuando solo la estación principal detecta un evento\n",
    "    time_trigger_all: list\n",
    "        Lista que contiene tiempos cuando todas las estaciones detectan un evento\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Coordenadas (latitud, longitud) de las estaciones\n",
    "    coord_main = coords_st[0]\n",
    "    coord_adj_1 = coords_st[1]\n",
    "    coord_adj_2 = coords_st[2]\n",
    "\n",
    "    # Distancia entre las estaciones\n",
    "    d_main_adj1 = geodesic(coord_main, coord_adj_1).kilometers\n",
    "    d_main_adj2 = geodesic(coord_main, coord_adj_2 ).kilometers\n",
    "    d_adj1_adj2 = geodesic(coord_adj_1 , coord_adj_2 ).kilometers\n",
    "\n",
    "    # Tiempo de llegada de la onda P a las estaciones\n",
    "    t_P_main_adj1 = d_main_adj1 / v_P\n",
    "    t_P_main_adj2 = d_main_adj2 / v_P\n",
    "    t_P_adj1_adj2 = d_adj1_adj2 / v_P\n",
    "\n",
    "    # Elección de canal para cada estación. \n",
    "    tr_main = st_main.select(channel='HHZ')[0]\n",
    "    tr_adj_1 = adj_st_1.select(channel='HHZ')[0]\n",
    "    tr_adj_2 = adj_st_2.select(channel='HHZ')[0]\n",
    "\n",
    "    # Frecuencia de muestreo\n",
    "    fs = tr_main.stats.sampling_rate\n",
    "\n",
    "    # Convertir los tamaños de ventana a muestras\n",
    "    muestras_10s = int(ventana_10s * fs)\n",
    "    muestras_30s = int(ventana_30s * fs)\n",
    "\n",
    "    # Inicializar el cálculo STA/LTA para los primeros 30 segundos de la traza.\n",
    "    cft_main = inicializar_sta_lta(tr_main, int(nsta * fs), int(nlta * fs))\n",
    "    initial_tr_main = tr_main.slice(endtime=tr_main.stats.starttime + ventana_30s)\n",
    "\n",
    "    time_trigger_main = []\n",
    "    time_trigger_all = []\n",
    "\n",
    "    \n",
    "    for i in range(10, len(tr_main), muestras_10s):\n",
    "        # Tomar la sección actual de 30 segundos\n",
    "        end_window = i + muestras_30s\n",
    "        if end_window > len(tr_main):\n",
    "            #print(end_window)\n",
    "            break\n",
    "        new_tr_main = tr_main.slice(starttime = tr_main.stats.starttime + i/fs, endtime = tr_main.stats.starttime + end_window/fs)\n",
    "        cft_main = actualizar_sta_lta(cft_main, initial_tr_main , new_tr_main, int(nsta * fs), int(nlta * fs))\n",
    "\n",
    "        # Si se activa se plotea\n",
    "        if np.any(cft_main > thr_on):\n",
    "            # No aseguramos de que el tiempo de inicio del sismo no se haya registrado antes\n",
    "            if new_tr_main.stats.starttime not in time_trigger_main:\n",
    "                time_trigger_main.append(new_tr_main.stats.starttime)\n",
    "            \n",
    "            #plot_trigger(nueva_traza,cft_main, thr_on, thr_off)\n",
    "            #time_trigger_main.append(new_tr_main.stats.starttime)\n",
    "\n",
    "            # Verificar si las estaciones adyacentes también detectan un sismo en ese intervalo de tiempo\n",
    "            initial_tr_adj_1 = tr_adj_1.slice(starttime = new_tr_main.stats.starttime, endtime = new_tr_main.stats.endtime)\n",
    "            initial_tr_adj_2 = tr_adj_2.slice(starttime = new_tr_main.stats.starttime, endtime = new_tr_main.stats.endtime)\n",
    "            cft_adj_1 = inicializar_sta_lta(initial_tr_adj_1, int(nsta * fs), int(nlta * fs))\n",
    "            cft_adj_2 = inicializar_sta_lta(initial_tr_adj_2, int(nsta * fs), int(nlta * fs))\n",
    "            \n",
    "            for j in range(math.ceil(max(t_P_main_adj1, t_P_main_adj2)/10)+1):\n",
    "                #print(j*muestras_10s, (j+1)*muestras_30s)\n",
    "                new_tr_adj_1 = tr_adj_1.slice(starttime = new_tr_main.stats.starttime + j*ventana_10s, endtime = new_tr_main.stats.endtime + j*ventana_10s)\n",
    "                new_tr_adj_2 = tr_adj_2.slice(starttime = initial_tr_adj_2.stats.starttime + j*ventana_10s, endtime = new_tr_main.stats.endtime + j*ventana_10s)\n",
    "                cfr_adj_1 = actualizar_sta_lta(cft_adj_1, initial_tr_adj_1, new_tr_adj_1, int(nsta * fs), int(nlta * fs))\n",
    "                cfr_adj_2 = actualizar_sta_lta(cft_adj_2, initial_tr_adj_2, new_tr_adj_2, int(nsta * fs), int(nlta * fs))\n",
    "\n",
    "                if np.any(cft_adj_1 > thr_on) and np.any(cft_adj_2 > thr_on):\n",
    "                    #plot_trigger(new_tr_main,cft_main, thr_on, thr_off)\n",
    "                    #initial_tr_adj_1 = new_tr_adj_1\n",
    "                    #initial_tr_adj_2 = new_tr_adj_2\n",
    "                    if new_tr_main.stats.starttime not in time_trigger_all:\n",
    "                        time_trigger_all.append(new_tr_main.stats.starttime)\n",
    "    \n",
    "\n",
    "            initial_tr_adj_1 = new_tr_adj_1\n",
    "            initial_tr_adj_2 = new_tr_adj_2\n",
    "\n",
    "\n",
    "        initial_tr_main  = new_tr_main\n",
    "        \n",
    "    return time_trigger_main, time_trigger_all\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Junta los archivos por carpeta. Queda un diccionario que tiene como llave la carpeta, \n",
    "# y como valor una lista con los paths a los archivos de esa carpeta.\n",
    "def sort_files(file_dic, extension):\n",
    "    # Diccionario para almacenar los archivos por carpeta\n",
    "    grouped_files = defaultdict(list)\n",
    "    key_names = []\n",
    "    for file in file_dic[extension]:\n",
    "        # Extraer la carpeta del path del archivo\n",
    "        parts = file.split(\"\\\\\")\n",
    "        folder = parts[-2]  # La carpeta es el penúltimo elemento en el path\n",
    "        if [folder] not in key_names:\n",
    "            key_names.append([folder])\n",
    "        # Agrupar los archivos\n",
    "        grouped_files[folder].append(file)\n",
    "\n",
    "    key_names = list(itertools.chain(*key_names))\n",
    "    return grouped_files, key_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordenadas (latitud, longitud) de las estaciones\n",
    "coord_C010 = (-29.24, -71.46)\n",
    "coord_AC04 = (-28.20, -71.07)\n",
    "coord_AC05 = (-28.84, -70.27)\n",
    "\n",
    "\n",
    "# Distancia entre las estaciones\n",
    "d_AC04_AC05 = geodesic(coord_AC04, coord_AC05).kilometers\n",
    "d_AC04_C010 = geodesic(coord_AC04, coord_C010).kilometers\n",
    "d_AC05_C010 = geodesic(coord_AC05, coord_C010).kilometers\n",
    "\n",
    "# Velocidad de propagación de las ondas P en kilometros por segundo\n",
    "v_P = 8.046\n",
    "\n",
    "# Tiempo de llegada de la onda P a las estaciones\n",
    "t_P_AC04_AC05 = d_AC04_AC05 / v_P\n",
    "t_P_AC05_C010 = d_AC05_C010 / v_P\n",
    "t_P_AC04_C010 = d_AC04_C010 / v_P\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esto se usa si se quiere usar los archivos de 24hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estación principal\n",
    "main_st = files_24hrs_ch[key_names_24hrs[2]]\n",
    "st_main = read(main_st[0])\n",
    "st_main += read(main_st[1])\n",
    "st_main += read(main_st[2])\n",
    "st_main.filter('bandpass', freqmin=4.0, freqmax=10.0, corners=1, zerophase=True) \n",
    "print(st_main.select(channel='HHZ'))\n",
    "\n",
    "#estación adyacente\n",
    "adj_st_1 = files_24hrs_ch[key_names_24hrs[0]]\n",
    "st_adj_1 = read(adj_st_1[0])\n",
    "st_adj_1 += read(adj_st_1[1])\n",
    "st_adj_1 += read(adj_st_1[2])\n",
    "st_adj_1.filter('bandpass', freqmin=4.0, freqmax=10.0, corners=1, zerophase=True)\n",
    "print(st_adj_1.select(channel='HHZ'))\n",
    "\n",
    "#estación adyacente\n",
    "adj_st_2 = files_24hrs_ch[key_names_24hrs[1]]\n",
    "st_adj_2 = read(adj_st_2[0])\n",
    "st_adj_2 += read(adj_st_2[1])\n",
    "st_adj_2 += read(adj_st_2[2])\n",
    "st_adj_2.filter('bandpass', freqmin=4.0, freqmax=10.0, corners=1, zerophase=True)\n",
    "print(st_adj_2.select(channel='HHZ'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esto es para una estación principal y 2 adyacentes, ahora estoy viendo para un número variable de estaciones adyacentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_picking(st_main, adj_st_1, adj_st_2, ventana_10s, ventana_30s, nsta, nlta, v_P, coords_st, thr_on, thr_off):\n",
    "    \"\"\"\n",
    "    Función que realiza el picking de la onda P. En caso de que se detecte un sismo en las estación principal,\n",
    "    se verifica que las estaciones adyacentes también lo detecten.\n",
    "\n",
    "    Entradas:\n",
    "    ----------\n",
    "    st_main: obspy.core.stream.Stream\n",
    "        Stream de la estación principal.\n",
    "    adj_st_1: obspy.core.stream.Stream\n",
    "        Stream de la estación adyacente 1.\n",
    "    adj_st_2: obspy.core.stream.Stream\n",
    "        Stream de la estación adyacente 2.\n",
    "    ventana_10s: int\n",
    "        Tiempo de la ventana en segundos donde se aplica el STA/LTA.\n",
    "    ventana_30s: int\n",
    "        Tiempo de la señal en segundos que se analiza en cada iteración.\n",
    "    nsta: int\n",
    "        Largo del short time average en segundos.\n",
    "    nlta: int\n",
    "        Largo del long time average en segundos.\n",
    "    v_P: float\n",
    "        Velocidad de propagación de la onda P en km/s.\n",
    "    coords_st: list\n",
    "        Coordenadas (latitud, longitud) de las estaciones.\n",
    "    \n",
    "    Salidas:\n",
    "    ----------\n",
    "    time_trigger_main: list\n",
    "        Lista que contiene tiempos cuando solo la estación principal detecta un evento\n",
    "    time_trigger_all: list\n",
    "        Lista que contiene tiempos cuando todas las estaciones detectan un evento\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Coordenadas (latitud, longitud) de las estaciones\n",
    "    coord_main = coords_st[0]\n",
    "    coord_adj_1 = coords_st[1]\n",
    "    coord_adj_2 = coords_st[2]\n",
    "\n",
    "    # Distancia entre las estaciones\n",
    "    d_main_adj1 = geodesic(coord_main, coord_adj_1).kilometers\n",
    "    d_main_adj2 = geodesic(coord_main, coord_adj_2 ).kilometers\n",
    "    d_adj1_adj2 = geodesic(coord_adj_1 , coord_adj_2 ).kilometers\n",
    "\n",
    "    # Tiempo de llegada de la onda P a las estaciones\n",
    "    t_P_main_adj1 = d_main_adj1 / v_P\n",
    "    t_P_main_adj2 = d_main_adj2 / v_P\n",
    "    t_P_adj1_adj2 = d_adj1_adj2 / v_P\n",
    "\n",
    "    # Elección de canal para cada estación. \n",
    "    tr_main = st_main.select(channel='BHZ')[0]\n",
    "    tr_adj_1 = adj_st_1.select(channel='BHZ')[0]\n",
    "    tr_adj_2 = adj_st_2.select(channel='BHZ')[0]\n",
    "\n",
    "    # Frecuencia de muestreo\n",
    "    fs = tr_main.stats.sampling_rate\n",
    "\n",
    "    # Convertir los tamaños de ventana a muestras\n",
    "    muestras_10s = int(ventana_10s * fs)\n",
    "    muestras_30s = int(ventana_30s * fs)\n",
    "\n",
    "    # Inicializar el cálculo STA/LTA para los primeros 30 segundos de la traza.\n",
    "    cft_main = inicializar_sta_lta(tr_main, int(nsta * fs), int(nlta * fs))\n",
    "    initial_tr_main = tr_main.slice(endtime=tr_main.stats.starttime + ventana_30s)\n",
    "\n",
    "    time_trigger_main = []\n",
    "    time_trigger_all = []\n",
    "\n",
    "    for i in range(10, len(tr_main), muestras_10s):\n",
    "        # Tomar la sección actual de 30 segundos\n",
    "        end_window = i + muestras_30s\n",
    "        if end_window > len(tr_main):\n",
    "            break\n",
    "        new_tr_main = tr_main.slice(starttime = tr_main.stats.starttime + i/fs, endtime = tr_main.stats.starttime + end_window/fs)\n",
    "        cft_main = actualizar_sta_lta(cft_main, initial_tr_main , new_tr_main, int(nsta * fs), int(nlta * fs))\n",
    "\n",
    "        # Si se activa se plotea\n",
    "        if np.any(cft_main > thr_on):\n",
    "            # Convertimos starttime a una cadena que solo contiene la fecha, la hora y los minutos\n",
    "            time_main_str = new_tr_main.stats.starttime.strftime(\"%Y-%m-%dT%H:%M\")\n",
    "            \n",
    "            # Creamos una lista separada para las comparaciones\n",
    "            time_trigger_main_comp = [t.strftime(\"%Y-%m-%dT%H:%M\") for t in time_trigger_main]\n",
    "            \n",
    "            # No aseguramos de que el tiempo de inicio del sismo no se haya registrado antes\n",
    "            if time_main_str not in time_trigger_main_comp:\n",
    "                time_trigger_main.append(new_tr_main.stats.starttime)\n",
    "            \n",
    "            #plot_trigger(nueva_traza,cft_main, thr_on, thr_off)\n",
    "            #time_trigger_main.append(new_tr_main.stats.starttime)\n",
    "\n",
    "            # Verificar si las estaciones adyacentes también detectan un sismo en ese intervalo de tiempo\n",
    "            initial_tr_adj_1 = tr_adj_1.slice(starttime = new_tr_main.stats.starttime, endtime = new_tr_main.stats.endtime)\n",
    "            initial_tr_adj_2 = tr_adj_2.slice(starttime = new_tr_main.stats.starttime, endtime = new_tr_main.stats.endtime)\n",
    "            cft_adj_1 = inicializar_sta_lta(initial_tr_adj_1, int(nsta * fs), int(nlta * fs))\n",
    "            cft_adj_2 = inicializar_sta_lta(initial_tr_adj_2, int(nsta * fs), int(nlta * fs))\n",
    "            \n",
    "            for j in range(math.ceil(max(t_P_main_adj1, t_P_main_adj2)/10)+1):\n",
    "                #print(j*muestras_10s, (j+1)*muestras_30s)\n",
    "                new_tr_adj_1 = tr_adj_1.slice(starttime = new_tr_main.stats.starttime + j*ventana_10s, endtime = new_tr_main.stats.endtime + j*ventana_10s)\n",
    "                new_tr_adj_2 = tr_adj_2.slice(starttime = new_tr_main.stats.starttime + j*ventana_10s, endtime = new_tr_main.stats.endtime + j*ventana_10s)\n",
    "                cft_adj_1 = actualizar_sta_lta(cft_adj_1, initial_tr_adj_1, new_tr_adj_1, int(nsta * fs), int(nlta * fs))\n",
    "                cft_adj_2 = actualizar_sta_lta(cft_adj_2, initial_tr_adj_2, new_tr_adj_2, int(nsta * fs), int(nlta * fs))\n",
    "\n",
    "                if np.any(cft_adj_1 > thr_on) and np.any(cft_adj_2 > thr_on):\n",
    "                    #plot_trigger(new_tr_main,cft_main, thr_on, thr_off)\n",
    "                    #initial_tr_adj_1 = new_tr_adj_1\n",
    "                    #initial_tr_adj_2 = new_tr_adj_2\n",
    "                    time_all_str = new_tr_main.stats.starttime.strftime(\"%Y-%m-%dT%H:%M\")\n",
    "                    time_trigger_all_comp = [t.strftime(\"%Y-%m-%dT%H:%M\") for t in time_trigger_all]\n",
    "                    if time_all_str not in time_trigger_all_comp:\n",
    "                        time_trigger_all.append(new_tr_main.stats.starttime)\n",
    "    \n",
    "\n",
    "            initial_tr_adj_1 = new_tr_adj_1\n",
    "            initial_tr_adj_2 = new_tr_adj_2\n",
    "\n",
    "\n",
    "        initial_tr_main  = new_tr_main\n",
    "        \n",
    "    return time_trigger_main, time_trigger_all\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Código para obtener en time_events_xlsx.txt solo los tiempos de evntos_catalogo.xlsx\n",
    "df = pd.read_excel('24hrs basura/evntos _catalogo.xlsx')\n",
    "times = df['Fecha UTC'].tolist()\n",
    "# Convierte la lista al formato UTC\n",
    "formatted_times = [time.strftime('%Y-%m-%dT%H:%M:%S') for time in times if pd.notnull(time)]\n",
    "with open('times_events_xlsx.txt', 'w') as archivo:\n",
    "    archivo.write('\\n'.join(formatted_times))\n",
    "\n",
    "#Código para obtener en time_events.txt solo los tiempos de query.txt\n",
    "with open(f'24hrs basura\\query.txt', 'r') as archivo:\n",
    "    lines = archivo.readlines()\n",
    "times = [line.split('|')[1] for line in lines]\n",
    "with open('times_events.txt', 'w') as archivo:\n",
    "    archivo.write('\\n'.join(times)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# rango de parámetros a probar\n",
    "nsta_values = [1.5, 2, 2.5, 3]\n",
    "nlta_values = [10, 12, 15, 20]\n",
    "thr_on_values = [3.5, 4, 5, 5.8]\n",
    "thr_off = 3\n",
    "\n",
    "# inicialización de los mejores parámetros y el mejor resultado\n",
    "best_params = (nsta_values[0], nlta_values[0], thr_on_values[0])\n",
    "best_result = -float('inf')  # El resultado más alto es el mejor \n",
    "\n",
    "# Calcular el número total de iteraciones\n",
    "total = len(nsta_values) * len(nlta_values) * len(thr_on_values)\n",
    "\n",
    "# Crear un objeto tqdm\n",
    "pbar = tqdm(total=total)\n",
    "\n",
    "# se itera sobre los parámetros\n",
    "for nsta in nsta_values:\n",
    "    for nlta in nlta_values:\n",
    "        for thr_on in thr_on_values:\n",
    "            # Llamar a la función P_picking con los parámetros actuales\n",
    "            time_main, time_all = P_picking(stations, ventana_10s, ventana_30s, nsta, nlta, v_P, coord_list, thr_on, thr_off)\n",
    "            \n",
    "            # Guardar los tiempos predichos\n",
    "            with open('time_trigger.txt', 'w') as archivo:\n",
    "                archivo.write('\\n'.join(str(time) for time in time_all))\n",
    "            \n",
    "            # Leer los tiempos reales y predichos\n",
    "            with open('times_events_xlsx.txt', 'r') as f:\n",
    "                tiempos_reales = [datetime.strptime(line.strip(), '%Y-%m-%dT%H:%M:%S') for line in f]\n",
    "            with open('time_trigger.txt', 'r') as f:\n",
    "                tiempos_predichos = [datetime.strptime(line.strip(), '%Y-%m-%dT%H:%M:%S.%fZ') for line in f]\n",
    "            \n",
    "            # Calcular los conjuntos de tiempos reales y predichos\n",
    "            conjunto_reales = set([t.replace(second=0) for t in tiempos_reales])\n",
    "            conjunto_predichos = set([t.replace(second=0, microsecond=0) for t in tiempos_predichos])\n",
    "            \n",
    "            # Calcular los verdaderos positivos, falsos positivos y falsos negativos\n",
    "            verdaderos_positivos = conjunto_reales & conjunto_predichos\n",
    "            falsos_positivos = conjunto_predichos - conjunto_reales\n",
    "            falsos_negativos = conjunto_reales - conjunto_predichos\n",
    "            \n",
    "            # Calcular el resultado (por ejemplo, el número de falsos positivos). Usar recall como métrica\n",
    "            result = len(verdaderos_positivos) / (len(verdaderos_positivos) + len(falsos_negativos))  # Aquí puedes cambiar la métrica de acuerdo a tus necesidades\n",
    "            \n",
    "            # Si el resultado actual es mejor que el mejor resultado hasta ahora, actualizar los mejores parámetros y el mejor resultado\n",
    "            if result > best_result:\n",
    "                best_params = (nsta, nlta, thr_on, thr_off)\n",
    "                best_result = result\n",
    "            # Actualizar la barra de progreso\n",
    "            pbar.update()\n",
    "\n",
    "pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCION OPTIMIZE PARAMETERS QUE SE QUE FUNCIONA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_parameters(nsta_values, nlta_values, thr_on_values, thr_off, stations, ventana_10s, ventana_30s, v_P, coord_list):\n",
    "    # Diccionario para almacenar los mejores parámetros y el resultado de f1-score\n",
    "    best_params = {}\n",
    "\n",
    "    # Número total de iteraciones\n",
    "    total = len(nsta_values) * len(nlta_values) * len(thr_on_values)\n",
    "\n",
    "    pbar = tqdm(total=total, leave=True)\n",
    "\n",
    "    with open('times_events_24hrs.txt', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # Saltar la cabecera\n",
    "        tiempos_reales = [datetime.strptime(row[1], '%Y-%m-%dT%H:%M:%S') for row in reader]\n",
    "\n",
    "    # se itera sobre los parámetros\n",
    "    for nsta, nlta, thr_on in product(nsta_values, nlta_values, thr_on_values):\n",
    "        # Llamar a la función P_picking con los parámetros actuales\n",
    "        time_main, time_all = P_picking(stations, ventana_10s, ventana_30s, nsta, nlta, v_P, coord_list, thr_on, thr_off)\n",
    "\n",
    "        # Guardar los tiempos predichos\n",
    "        tiempos_predichos = [datetime.strptime(str(time), '%Y-%m-%dT%H:%M:%S.%fZ') for time in time_all]\n",
    "        \n",
    "        # Calcular los conjuntos de tiempos reales y predichos\n",
    "        conjunto_reales = set([t.replace(second=0) for t in tiempos_reales])\n",
    "        conjunto_predichos = set([t.replace(second=0, microsecond=0) for t in tiempos_predichos])\n",
    "        \n",
    "        # Calcular los verdaderos positivos, falsos positivos y falsos negativos\n",
    "        verdaderos_positivos = conjunto_reales & conjunto_predichos\n",
    "        falsos_positivos = conjunto_predichos - conjunto_reales\n",
    "        falsos_negativos = conjunto_reales - conjunto_predichos\n",
    "        \n",
    "        # Usar F1-score como métrica de evaluación para minimizar los falsos positivos y falsos negativos\n",
    "        if verdaderos_positivos:\n",
    "            presicion = len(verdaderos_positivos) / (len(verdaderos_positivos) + len(falsos_positivos))\n",
    "            recall = len(verdaderos_positivos) / (len(verdaderos_positivos) + len(falsos_negativos))\n",
    "            f1_score = 2 * (presicion * recall) / (presicion + recall)\n",
    "        else:\n",
    "            f1_score = 0  # Si no hay verdaderos positivos ni falsos positivos, la precisión es 0\n",
    "\n",
    "        # Si el resultado actual es mejor que el mejor resultado hasta ahora, actualizar los mejores parámetros y el mejor resultado\n",
    "        if len(best_params) < 5 or f1_score > min(best_params.values()):\n",
    "            if len(best_params) == 5:\n",
    "                # eliminar la combinación de parámetros con el peor resultado\n",
    "                worst_key = min(best_params, key=best_params.get)\n",
    "                del best_params[worst_key]   \n",
    "            # agregar la nueva combinación de parámetros y su resultado al diccionario\n",
    "            best_params[(nsta, nlta, thr_on, thr_off)] = f1_score \n",
    "            ic(best_params)\n",
    "\n",
    "        # Actualizar la barra de progreso\n",
    "        pbar.update()\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Este es un intento de usar multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "# rango de parámetros a probar\n",
    "nsta_values = [1.5, 1.8, 2, 2.3 ,2.5, 2.8, 3, 3.5]\n",
    "nlta_values = [8, 10, 12, 15, 17, 20, 23, 25]\n",
    "thr_on_values = [3.5, 3.9, 4, 4.5, 5, 5.3, 5.5, 5.8]\n",
    "thr_off = 3 # solo sirve al momento de hacer plot_trigger, por lo que no es necesario cambiarlo para buscar eventos\n",
    "\n",
    "# Diccionario para almacenar los mejores parámetros y el resultado de f1-score\n",
    "best_params = {}\n",
    "\n",
    "# Número total de iteraciones\n",
    "total = len(nsta_values) * len(nlta_values) * len(thr_on_values)\n",
    "\n",
    "pbar = tqdm(total=total, leave=True)\n",
    "\n",
    "with open('times_events_24hrs.txt', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # Saltar la cabecera\n",
    "    tiempos_reales = [datetime.strptime(row[1], '%Y-%m-%dT%H:%M:%S') for row in reader]\n",
    "\n",
    "# Función para calcular el f1-score para una combinación de parámetros\n",
    "def calculate_f1_score(params):\n",
    "    nsta, nlta, thr_on = params\n",
    "    # Llamar a la función P_picking con los parámetros actuales\n",
    "    time_main, time_all = P_picking(stations, ventana_10s, ventana_30s, nsta, nlta, v_P, coord_list, thr_on, thr_off)\n",
    "\n",
    "    # Guardar los tiempos predichos\n",
    "    tiempos_predichos = [datetime.strptime(str(time), '%Y-%m-%dT%H:%M:%S.%fZ') for time in time_all]\n",
    "    \n",
    "    # Calcular los conjuntos de tiempos reales y predichos\n",
    "    conjunto_reales = set([t.replace(second=0) for t in tiempos_reales])\n",
    "    conjunto_predichos = set([t.replace(second=0, microsecond=0) for t in tiempos_predichos])\n",
    "    \n",
    "    # Calcular los verdaderos positivos, falsos positivos y falsos negativos\n",
    "    verdaderos_positivos = conjunto_reales & conjunto_predichos\n",
    "    falsos_positivos = conjunto_predichos - conjunto_reales\n",
    "    falsos_negativos = conjunto_reales - conjunto_predichos\n",
    "    \n",
    "    # Usar F1-score como métrica de evaluación para minimizar los falsos positivos y falsos negativos\n",
    "    if len(verdaderos_positivos) > 0:\n",
    "        presicion = len(verdaderos_positivos) / (len(verdaderos_positivos) + len(falsos_positivos))\n",
    "        recall = len(verdaderos_positivos) / (len(verdaderos_positivos) + len(falsos_negativos))\n",
    "        f1_score = 2 * (presicion * recall) / (presicion + recall)\n",
    "    else:\n",
    "        f1_score = 0  # Si no hay verdaderos positivos ni falsos positivos, la precisión es 0\n",
    "\n",
    "    return (nsta, nlta, thr_on, thr_off), f1_score\n",
    "\n",
    "# Crear una lista de todas las combinaciones de parámetros\n",
    "params = [(nsta, nlta, thr_on) for nsta in nsta_values for nlta in nlta_values for thr_on in thr_on_values]\n",
    "\n",
    "# Crear un pool de trabajadores y calcular el f1-score para todas las combinaciones de parámetros\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    for params, f1_score in executor.map(calculate_f1_score, params):\n",
    "        # Si el resultado actual es mejor que el mejor resultado hasta ahora, actualizar los mejores parámetros y el mejor resultado\n",
    "        if len(best_params) < 5 or f1_score > min(best_params.values()):\n",
    "            if len(best_params) == 5:\n",
    "                # eliminar la combinación de parámetros con el peor resultado\n",
    "                worst_key = min(best_params, key=best_params.get)\n",
    "                del best_params[worst_key]   \n",
    "            # agregar la nueva combinación de parámetros y su resultado al diccionario\n",
    "            best_params[params] = f1_score \n",
    "            ic(best_params)\n",
    "\n",
    "        # Actualizar la barra de progreso\n",
    "        pbar.update()\n",
    "\n",
    "pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lo siguiente es el código que funciona para buscar los parámetros usando fuerza bruta. Es la última versión antes de ver como hacerlo más óptimo partiendo por paralelización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# rango de parámetros a probar\n",
    "nsta_values = [1.5, 1.8, 2, 2.3 ,2.5, 2.8, 3, 3.5]\n",
    "nlta_values = [8, 10, 12, 15, 17, 20, 23, 25]\n",
    "thr_on_values = [3.5, 3.9, 4, 4.5, 5, 5.3, 5.5, 5.8]\n",
    "thr_off = 3 # solo sirve al momento de hacer plot_trigger, por lo que no es necesario cambiarlo para buscar eventos\n",
    "\n",
    "# Diccionario para almacenar los mejores parámetros y el resultado de f1-score\n",
    "best_params = {}\n",
    "\n",
    "# Número total de iteraciones\n",
    "total = len(nsta_values) * len(nlta_values) * len(thr_on_values)\n",
    "\n",
    "pbar = tqdm(total=total, leave=True)\n",
    "\n",
    "with open('times_events_24hrs.txt', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # Saltar la cabecera\n",
    "    tiempos_reales = [datetime.strptime(row[1], '%Y-%m-%dT%H:%M:%S') for row in reader]\n",
    "\n",
    "# se itera sobre los parámetros\n",
    "for nsta, nlta, thr_on in product(nsta_values, nlta_values, thr_on_values):\n",
    "    # Llamar a la función P_picking con los parámetros actuales\n",
    "    time_main, time_all = P_picking(stations, ventana_10s, ventana_30s, nsta, nlta, v_P, coord_list, thr_on, thr_off)\n",
    "\n",
    "    # Guardar los tiempos predichos\n",
    "    tiempos_predichos = [datetime.strptime(str(time), '%Y-%m-%dT%H:%M:%S.%fZ') for time in time_all]\n",
    "    \n",
    "    # Calcular los conjuntos de tiempos reales y predichos\n",
    "    conjunto_reales = set([t.replace(second=0) for t in tiempos_reales])\n",
    "    conjunto_predichos = set([t.replace(second=0, microsecond=0) for t in tiempos_predichos])\n",
    "    \n",
    "    # Calcular los verdaderos positivos, falsos positivos y falsos negativos\n",
    "    verdaderos_positivos = conjunto_reales & conjunto_predichos\n",
    "    falsos_positivos = conjunto_predichos - conjunto_reales\n",
    "    falsos_negativos = conjunto_reales - conjunto_predichos\n",
    "    \n",
    "    # Usar F1-score como métrica de evaluación para minimizar los falsos positivos y falsos negativos\n",
    "    if verdaderos_positivos:\n",
    "        presicion = len(verdaderos_positivos) / (len(verdaderos_positivos) + len(falsos_positivos))\n",
    "        recall = len(verdaderos_positivos) / (len(verdaderos_positivos) + len(falsos_negativos))\n",
    "        f1_score = 2 * (presicion * recall) / (presicion + recall)\n",
    "    else:\n",
    "        f1_score = 0  # Si no hay verdaderos positivos ni falsos positivos, la precisión es 0\n",
    "\n",
    "    # Si el resultado actual es mejor que el mejor resultado hasta ahora, actualizar los mejores parámetros y el mejor resultado\n",
    "    if len(best_params) < 5 or f1_score > min(best_params.values()):\n",
    "        if len(best_params) == 5:\n",
    "            # eliminar la combinación de parámetros con el peor resultado\n",
    "            worst_key = min(best_params, key=best_params.get)\n",
    "            del best_params[worst_key]   \n",
    "        # agregar la nueva combinación de parámetros y su resultado al diccionario\n",
    "        best_params[(nsta, nlta, thr_on, thr_off)] = f1_score \n",
    "        ic(best_params)\n",
    "\n",
    "    # Actualizar la barra de progreso\n",
    "    pbar.update()\n",
    "\n",
    "pbar.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTRA FORMA DE HACER EL MÓDULO optimize_parameters.py usando multiprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def worker(nsta, nlta, thr_on, thr_off, stations, ventana_10s, ventana_30s, v_P, coord_list, tiempos_reales):\n",
    "    # Llamar a la función P_picking con los parámetros actuales\n",
    "    time_main, time_all = P_picking(stations, ventana_10s, ventana_30s, nsta, nlta, v_P, coord_list, thr_on, thr_off)\n",
    "\n",
    "    # Guardar los tiempos predichos\n",
    "    tiempos_predichos = [datetime.strptime(str(time), '%Y-%m-%dT%H:%M:%S.%fZ') for time in time_all]\n",
    "    \n",
    "    # Calcular los conjuntos de tiempos reales y predichos\n",
    "    conjunto_reales = set([t.replace(second=0) for t in tiempos_reales])\n",
    "    conjunto_predichos = set([t.replace(second=0, microsecond=0) for t in tiempos_predichos])\n",
    "    \n",
    "    # Calcular los verdaderos positivos, falsos positivos y falsos negativos\n",
    "    verdaderos_positivos = conjunto_reales & conjunto_predichos\n",
    "    falsos_positivos = conjunto_predichos - conjunto_reales\n",
    "    falsos_negativos = conjunto_reales - conjunto_predichos\n",
    "    \n",
    "    # Usar F1-score como métrica de evaluación para minimizar los falsos positivos y falsos negativos\n",
    "    if verdaderos_positivos:\n",
    "        presicion = len(verdaderos_positivos) / (len(verdaderos_positivos) + len(falsos_positivos))\n",
    "        recall = len(verdaderos_positivos) / (len(verdaderos_positivos) + len(falsos_negativos))\n",
    "        f1_score = 2 * (presicion * recall) / (presicion + recall)\n",
    "    else:\n",
    "        f1_score = 0  # Si no hay verdaderos positivos ni falsos positivos, la precisión es 0\n",
    "\n",
    "    return (nsta, nlta, thr_on, thr_off), f1_score\n",
    "\n",
    "def optimize_parameters(nsta_values, nlta_values, thr_on_values, thr_off, stations, ventana_10s, ventana_30s, v_P, coord_list):\n",
    "    # Diccionario para almacenar los mejores parámetros y el resultado de f1-score\n",
    "    best_params = {}\n",
    "\n",
    "    # Número total de iteraciones\n",
    "    total = len(nsta_values) * len(nlta_values) * len(thr_on_values)\n",
    "\n",
    "    pbar = tqdm(total=total, leave=True)\n",
    "\n",
    "    with open('times_events_24hrs.txt', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # Saltar la cabecera\n",
    "        tiempos_reales = [datetime.strptime(row[1], '%Y-%m-%dT%H:%M:%S') for row in reader]\n",
    "\n",
    "    # se itera sobre los parámetros\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = {executor.submit(worker, nsta, nlta, thr_on, thr_off, stations, ventana_10s, ventana_30s, v_P, coord_list, tiempos_reales): (nsta, nlta, thr_on, thr_off) for nsta, nlta, thr_on in product(nsta_values, nlta_values, thr_on_values)}\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            params = futures[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "            except Exception as exc:\n",
    "                print('%r generated an exception: %s' % (params, exc))\n",
    "            else:\n",
    "                if len(best_params) < 5 or result[1] > min(best_params.values()):\n",
    "                    if len(best_params) == 5:\n",
    "                        # eliminar la combinación de parámetros con el peor resultado\n",
    "                        worst_key = min(best_params, key=best_params.get)\n",
    "                        del best_params[worst_key]   \n",
    "                    # agregar la nueva combinación de parámetros y su resultado al diccionario\n",
    "                    best_params[result[0]] = result[1] \n",
    "\n",
    "            # Actualizar la barra de progreso\n",
    "            pbar.update()\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    return best_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La siguiente es la función optimize_parameters que se que funciona\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def optimize_parameters(nsta_values, nlta_values, thr_on_values, thr_off, stations, ventana_10s, ventana_30s, v_P, coord_list):\n",
    "    # Diccionario para almacenar los mejores parámetros y el resultado de f1-score\n",
    "    best_params = {}\n",
    "\n",
    "    # Número total de iteraciones\n",
    "    total = len(nsta_values) * len(nlta_values) * len(thr_on_values)\n",
    "\n",
    "    pbar = tqdm(total=total, leave=True)\n",
    "\n",
    "    with open('times_events_24hrs.txt', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # Saltar la cabecera\n",
    "        tiempos_reales = [datetime.strptime(row[1], '%Y-%m-%dT%H:%M:%S') for row in reader]\n",
    "\n",
    "    # se itera sobre los parámetros\n",
    "    for nsta, nlta, thr_on in product(nsta_values, nlta_values, thr_on_values):\n",
    "        # Llamar a la función P_picking con los parámetros actuales\n",
    "        time_main, time_all = P_picking(stations, ventana_10s, ventana_30s, nsta, nlta, v_P, coord_list, thr_on, thr_off)\n",
    "\n",
    "        # Guardar los tiempos predichos\n",
    "        tiempos_predichos = [datetime.strptime(str(time), '%Y-%m-%dT%H:%M:%S.%fZ') for time in time_all]\n",
    "        \n",
    "        # Calcular los conjuntos de tiempos reales y predichos\n",
    "        conjunto_reales = set([t.replace(second=0) for t in tiempos_reales])\n",
    "        conjunto_predichos = set([t.replace(second=0, microsecond=0) for t in tiempos_predichos])\n",
    "        \n",
    "        # Calcular los verdaderos positivos, falsos positivos y falsos negativos\n",
    "        verdaderos_positivos = conjunto_reales & conjunto_predichos\n",
    "        falsos_positivos = conjunto_predichos - conjunto_reales\n",
    "        falsos_negativos = conjunto_reales - conjunto_predichos\n",
    "        \n",
    "        # Usar F1-score como métrica de evaluación para minimizar los falsos positivos y falsos negativos\n",
    "        if verdaderos_positivos:\n",
    "            presicion = len(verdaderos_positivos) / (len(verdaderos_positivos) + len(falsos_positivos))\n",
    "            recall = len(verdaderos_positivos) / (len(verdaderos_positivos) + len(falsos_negativos))\n",
    "            f1_score = 2 * (presicion * recall) / (presicion + recall)\n",
    "        else:\n",
    "            f1_score = 0  # Si no hay verdaderos positivos ni falsos positivos, la precisión es 0\n",
    "\n",
    "        # Si el resultado actual es mejor que el mejor resultado hasta ahora, actualizar los mejores parámetros y el mejor resultado\n",
    "        if len(best_params) < 5 or f1_score > min(best_params.values()):\n",
    "            if len(best_params) == 5:\n",
    "                # eliminar la combinación de parámetros con el peor resultado\n",
    "                worst_key = min(best_params, key=best_params.get)\n",
    "                del best_params[worst_key]   \n",
    "            # agregar la nueva combinación de parámetros y su resultado al diccionario\n",
    "            best_params[(nsta, nlta, thr_on, thr_off)] = f1_score \n",
    "            ic(best_params)\n",
    "\n",
    "        # Actualizar la barra de progreso\n",
    "        pbar.update()\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    return best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trigger_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
